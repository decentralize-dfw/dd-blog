Touch, the touch of Adam, or the message that came to Muhammad through the act of reading. These are gestures that appeal to the senses, forming the foundation of being human, and they are also the roots of the empirical knowledge we possess today. Touch, reading, wars, inventions, kingdoms, nations, stories—at the end of all of these, humankind has evolved into the era of the click. Knowledge once acquired through touch is now absorbed by tapping a digital screen or clicking a mouse. With a single click you can earn billions, lose everything, infect your computer with a virus and lose all your work, or—by clicking and scrolling through what you read—reconstruct yourself from scratch.


The same applies to agents. With a click, we can generate an identity, a character, nearly an entire life. A human being is born, grows up, and until the age of eighteen their identity is considered unsettled by society; they attend schools, work, eventually get a job. Now, with a few clicks, all of this unfolds autonomously, in minutes, even seconds. You copy a piece of text, and that becomes someone’s role, their character, their life. All with a click.


Click to wear, click to be. Since this is an avatar collection, the phrase is partly a pun on “ready to wear”—a digital reinterpretation. Yet the deeper meaning of the click lies in its resonance with biology: just as cells divide and multiply, a tree grows, a flower blooms, or the sun rises, sets, and turns into a full moon, clicking is the digital counterpart of a natural process. You click a link, and for thirty minutes you experience something three-dimensional and 360-degree. That click is equivalent to showering, putting on perfume, getting in the car, driving forty minutes, parking, leaving your coat at the cloakroom, buying a ticket, and finally experiencing a museum or performance. Or, it can be seen as the natural outcome of a generation that, after the plague of Covid, grew accustomed to the comfort of working from home and is now searching for new approaches to entertainment, art, and design.


Meanwhile, in today’s digitized world—where nearly all tools and interactions are absorbed by the internet and by rendering, and where algorithms have become the new governments and regulators—it has become nearly impossible to distinguish the real from the fake. This is equally true for the population of the internet itself. Once called bots, now called agents, they are part of this newly emerged ecosystem. At present, only a minority live this way, but in the near future, perhaps everyone will have their flights, doctor’s appointments, emails, fridge temperature, and dinner plans handled autonomously. Social media accounts and trading bots are already part of this shift.


I read a tweet that said: “Welcome to the hell of capitalism: people apply for jobs using AI, HR reviews those applications using AI, and therefore nobody gets a job.” Or another one: a California psychologist writes their patient’s words in real-time into a chat program and then relays only the safest suggestions back. This shows that agents and bots do not yet have seamless interfaces; they are still being manually patched and filtered. Solutions exist, and a small minority already use them daily. But mainstream tools are only ChatGPT or Grok—those are the “known” solutions. We are heading toward a world where every person and company will have an agent for each task, and those agents will communicate and transact with other agents. Just as no one truly “sits down to write an email” anymore, so too, in more complex ways, our work and life flows will be fully agent-driven. Which means, just as businesses have websites and individuals have social accounts, these agents must also have interfaces on the internet. Their interfaces are avatars. Whether your own copy, someone else, or the C2W2 avatars. Even now this is entirely possible—by linking an avatar’s portrait to an agent application, or placing its 3D body in the metaverse, you can assign it tasks.


The difference with C2W2 avatars lies in their design and philosophy: they emerge entirely from this paradigm shift. The volumes, textures, and bodies used in the collection are not random. Each can be thought of as a localized screenshot of a greater 360-degree sphere—multiple windows into the same moment of transformation.


And just as the avatars themselves demanded a different mode of presentation, the way they are shown also had to break away from PDFs or websites lined with horizontal JPEGs. The nature of the object, and the destiny of these designs, required a new form. Avatars—and the ideas they reference—are multi-windowed, variable, yet singular, arranged into a 360-degree digital narrative skeleton. This collection and its runway, while digging into concepts of zeitgeist and the future, is also a three-dimensional reimagining of our daily habit of scrolling vertically through thirty-second social clips that pump us with dopamine. Videos appear endlessly, but the algorithm already knows what it will feed you. That very mathematics sits beneath the runway. I believe this format lays the foundation for new-generation fashion shows, but at the same time it is an early preview of how everything on the internet—including social media—will soon be experienced.


The virtual runway consists of six chapters, thirty minutes in total, staged on Hyperfy, sequentially presenting various segments of the C2W2 collection. In a minimalist and dark space, under a circle of dramatic lights, more than fifty designed avatars are revealed one by one every thirty seconds, arranged into a single narrative. Across these six chapters, both the medium itself and we—humans, and now a newly emerging species of agents—are curated in their process of evolution through avatars and interactive sounds.


Narratively, the runway begins with the avatarization of painting—one of the most traditional mediums, with avatars inspired by masters like Francis Bacon and Matisse, designed with the aid of AI. In the second part, it explores the variations of digital fashion and design on “flat” avatars, probing their limits and experimenting with different personalities.


The third chapter is a hybrid of the first two—a historical continuation—where NFTs and notable figures merge with digital design, creating a deeper conceptual terrain. Here, familiar faces recontextualized reduce the “coolness” of mere spectacle, pushing the viewer into meaning itself.


In the fourth chapter, much like what the internet and AI did to us initially, the prior three parts are effectively reset. Through avatars generated entirely by AI, the runway erases and devalues everything we saw before. This mirrors the cheapening of “cool visuals” under the flood of AI-produced imagery, where hand-made labor loses its aura.


The fifth chapter sanctifies, in a minimalist way, the identity-dissolving nature of these new design possibilities—both for the designer and the user. Drawing on small references from the earlier chapters, it stages a kind of parametric, historical ascension, like the most sacred of avatars or the salvation of humanity itself. It evokes the loneliness of the individual after the material bombardment of chapter four, in search of meaning.


The final chapter shows no new avatar. Like a phoenix rising from its ashes, the runway closes with the rebirth of an idea, an institution, or perhaps anything at all. Strategically selected avatars from the previous five parts return, but altered—recognizable yet transformed. Unlike the recycled revival of 90s denim or 2000s looks, this is a deeper return to essence: not nostalgia, but a fragmented transformation of a simulated century condensed into thirty minutes. Here, the core theme is not the avatars or the clothes themselves, but the multidimensional narrative of AI, the metaverse, blockchain, belonging, and identity.


Final Note
All these transformations, these ideas, are not presented as neat “10 new concepts for your runway” after a ChatGPT session. They are observations, echoes of voices in the mind—organic transmissions of the human-digital metamorphosis, told first-hand. Just like this very text—begun in October 2024, carried into September 2025, and still awaiting the moment of its release—scattered and fragmented at times. Because in the end, neither the avatars nor the experience will be reduced by the viewer to “a quick summary” asked from a chat program. When the experience ends, the feelings the audience carries remain beyond code, with no biological equivalent yet written. Just as an AI that recommends meditation cannot meditate itself, the impressions left in the viewer are organic, immeasurable. They can only click, and watch.


This text, likewise, is nothing more than what the creator’s mind recorded while following the trail of their own pen.


